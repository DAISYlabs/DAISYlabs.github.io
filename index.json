[{"authors":["frederic-madesta \"Frederic Madesta\""],"categories":null,"content":"","date":1571788860,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1571788860,"objectID":"85f7b068658d947139535a3e0892c2ab","permalink":"https://DAISYlabs.github.io/authors/frederic-madesta/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/frederic-madesta/","section":"authors","summary":"","tags":null,"title":"Frederic Madesta","type":"authors"},{"authors":["ruediger-schmitz"],"categories":null,"content":"","date":1571788860,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1571788860,"objectID":"b894cadd57f1bfec154b876fc8a3fd3f","permalink":"https://DAISYlabs.github.io/authors/ruediger-schmitz/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ruediger-schmitz/","section":"authors","summary":"","tags":null,"title":"Rüdiger Schmitz","type":"authors"},{"authors":["nils-gessert"],"categories":null,"content":"","date":1567123200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567123200,"objectID":"dff49d73c01465faed52da98425618f2","permalink":"https://DAISYlabs.github.io/authors/nils-gessert/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/nils-gessert/","section":"authors","summary":"","tags":null,"title":"Nils Gessert","type":"authors"},{"authors":["thilo-sentker"],"categories":null,"content":"","date":1569888060,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1569888060,"objectID":"611691127a6eb12c94397601d9ec4d0d","permalink":"https://DAISYlabs.github.io/authors/thilo-sentker/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/thilo-sentker/","section":"authors","summary":"","tags":null,"title":"Thilo Sentker","type":"authors"},{"authors":["tobias-knopp"],"categories":null,"content":"","date":1533427200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1533427200,"objectID":"0f1661dceafe920e9a90296af7402bab","permalink":"https://DAISYlabs.github.io/authors/tobias-knopp/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/tobias-knopp/","section":"authors","summary":"","tags":null,"title":"Tobias Knopp","type":"authors"},{"authors":["maximilian-nielsen"],"categories":null,"content":"","date":1571788860,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1571788860,"objectID":"7314ec171cf14c695b151cb8c0d13c2e","permalink":"https://DAISYlabs.github.io/authors/maximilian-nielsen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/maximilian-nielsen/","section":"authors","summary":"","tags":null,"title":"Maximilian Nielsen","type":"authors"},{"authors":["rene-werner"],"categories":null,"content":"","date":1571788860,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1571788860,"objectID":"94973a1e213ce67040a329b1da6f4628","permalink":"https://DAISYlabs.github.io/authors/rene-werner/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/rene-werner/","section":"authors","summary":"","tags":null,"title":"René Werner","type":"authors"},{"authors":["ivo-baltruschat"],"categories":null,"content":"","date":1567123200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567123200,"objectID":"b8d477ee5d18aa0b83e0f3e57e06785c","permalink":"https://DAISYlabs.github.io/authors/ivo-baltruschat/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ivo-baltruschat/","section":"authors","summary":"","tags":null,"title":"Ivo Matteo Baltruschat","type":"authors"},{"authors":["mohsin-shaikh"],"categories":null,"content":"","date":1567123200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567123200,"objectID":"c69f3dc541e70ef3447d9cfb0882a601","permalink":"https://DAISYlabs.github.io/authors/mohsin-shaikh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/mohsin-shaikh/","section":"authors","summary":"","tags":null,"title":"Mohsin Shaikh","type":"authors"},{"authors":["helge-kniep"],"categories":null,"content":"","date":1558828800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1558828800,"objectID":"9c28747097bb3dca752afc359952391a","permalink":"https://DAISYlabs.github.io/authors/helge-kniep/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/helge-kniep/","section":"authors","summary":"","tags":null,"title":"Helge Kniep","type":"authors"},{"authors":["Nils Gessert","Maximilian Nielsen","Mohsin Shaikh","Ivo Matteo Baltruschat","Rüdiger Schmitz","René Werner"],"categories":null,"content":"Aim The goal for ISIC 2019: Task 1 is classify dermoscopic images with additional available meta-data (e.g. age, anatomical site, and sex) among nine different diagnostic categories.\nBackground Skin cancer is a major public health problem, with over 5,000,000 newly diagnosed cases in the United States every year. Melanoma is the deadliest form of skin cancer, responsible for an overwhelming majority of skin cancer deaths. In 2015, the global incidence of melanoma was estimated to be over 350,000 cases, with almost 60,000 deaths. Although the mortality is significant, when detected early, melanoma survival exceeds 95%.\nAbout Dermoscopy As pigmented lesions occurring on the surface of the skin, melanoma is amenable to early detection by expert visual inspection. It is also amenable to automated detection with image analysis. Given the widespread availability of high-resolution cameras, algorithms that can improve our ability to screen and detect troublesome lesions can be of great value. As a result, many centers have begun their own research efforts on automated analysis. However, a centralized, coordinated, and comparative effort across institutions has yet to be implemented. Dermoscopy is an imaging technique that eliminates the surface reflection of skin. By removing surface reflection, visualization of deeper levels of skin is enhanced. Prior research has shown that when used by expert dermatologists, dermoscopy provides improved diagnostic accuracy, in comparison to standard photography. As inexpensive consumer dermatoscope attachments for smart phones are beginning to reach the market, the opportunity for automated dermoscopic assessment algorithms to positively influence patient care increases.\nResults Challenge https://challenge2019.isic-archive.com/\n","date":1567123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567123200,"objectID":"05b38e90cf9bf210a25bdd09f3a3f405","permalink":"https://DAISYlabs.github.io/project/2019-isic-task2/","publishdate":"2019-08-30T00:00:00Z","relpermalink":"/project/2019-isic-task2/","section":"project","summary":"**1st rank of 16** unique teams in Task 2: Lesion diagnosis with images and metadata","tags":null,"title":"ISIC 2019: Skin Lesion Analysis Towards Melanoma Detection - Task 2","type":"project"},{"authors":["Nils Gessert","Maximilian Nielsen","Mohsin Shaikh","Ivo Matteo Baltruschat","Rüdiger Schmitz","René Werner"],"categories":null,"content":"Aim The goal for ISIC 2019: Task 1 is classify dermoscopic images without meta-data among nine different diagnostic categories:\n Melanoma Melanocytic nevus Basal cell carcinoma Actinic keratosis Benign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis) Dermatofibroma Vascular lesion Squamous cell carcinoma None of the others  Background Skin cancer is a major public health problem, with over 5,000,000 newly diagnosed cases in the United States every year. Melanoma is the deadliest form of skin cancer, responsible for an overwhelming majority of skin cancer deaths. In 2015, the global incidence of melanoma was estimated to be over 350,000 cases, with almost 60,000 deaths. Although the mortality is significant, when detected early, melanoma survival exceeds 95%.\nAbout Dermoscopy As pigmented lesions occurring on the surface of the skin, melanoma is amenable to early detection by expert visual inspection. It is also amenable to automated detection with image analysis. Given the widespread availability of high-resolution cameras, algorithms that can improve our ability to screen and detect troublesome lesions can be of great value. As a result, many centers have begun their own research efforts on automated analysis. However, a centralized, coordinated, and comparative effort across institutions has yet to be implemented. Dermoscopy is an imaging technique that eliminates the surface reflection of skin. By removing surface reflection, visualization of deeper levels of skin is enhanced. Prior research has shown that when used by expert dermatologists, dermoscopy provides improved diagnostic accuracy, in comparison to standard photography. As inexpensive consumer dermatoscope attachments for smart phones are beginning to reach the market, the opportunity for automated dermoscopic assessment algorithms to positively influence patient care increases.\nResults Challenge https://challenge2019.isic-archive.com/\n","date":1565913600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565913600,"objectID":"ffd706f58099b3c3b5ab91f1019a0c2d","permalink":"https://DAISYlabs.github.io/project/2019-isic-task1/","publishdate":"2019-08-16T00:00:00Z","relpermalink":"/project/2019-isic-task1/","section":"project","summary":"**1st rank of 64** unique teams in Task 1: Lesion diagnosis with images only","tags":null,"title":"ISIC 2019: Skin Lesion Analysis Towards Melanoma Detection - Task 1","type":"project"},{"authors":["Nils Gessert","Thilo Sentker","Frederic Madesta","Rüdiger Schmitz","Helge Kniep","Ivo Matteo Baltruschat","René Werner"],"categories":null,"content":"Aim Submit automated predictions of disease classification within dermoscopic images. Possible disease categories are:\n Melanoma Melanocytic nevus Basal cell carcinoma Actinic keratosis / Bowen’s disease (intraepithelial carcinoma) Benign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis) Dermatofibroma Vascular lesion  Background Skin cancer is the most common cancer globally, with melanoma being the most deadly form. Dermoscopy is a skin imaging modality that has demonstrated improvement for diagnosis of skin cancer compared to unaided visual inspection. However, clinicians should receive adequate training for those improvements to be realized. In order to make expertise more widely available, the International Skin Imaging Collaboration (ISIC) has developed the ISIC Archive, an international repository of dermoscopic images, for both the purposes of clinical training, and for supporting technical research toward automated algorithmic analysis by hosting the ISIC Challenges.\nResults Challenge https://challenge2018.isic-archive.com\n","date":1524787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524787200,"objectID":"c87eded95a8c001b1811d17aa716a5cd","permalink":"https://DAISYlabs.github.io/project/2018-isic-task3/","publishdate":"2018-04-27T00:00:00Z","relpermalink":"/project/2018-isic-task3/","section":"project","summary":"**2nd rank of 77** unique teams in Task 3: Lesion Diagnosis","tags":null,"title":"ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection - Task 3","type":"project"},{"authors":["Rüdiger Schmitz","Frederic Madesta","Maximilian Nielsen","René Werner"],"categories":null,"content":"Aim The goal of the challenge is to evaluate new and existing algorithms for viable tumor burden estimation in whole-slide images (WSIs).\nBackground The liver is a visceral organ most often involved in the metastatic spread of cancer. For the best practice, early diagnosis of liver cancer is important but many people don\u0026rsquo;t even know that they have hepatitis. Hepatocellular Carcinoma(HCC) represents about 90% of primary liver cancers and constitutes a major global health problem. The incidence of HCC is increasing both in Korea and worldwide; it is amongst the leading causes of cancer mortality globally. Between 1990 and 2015 newly diagnosed HCC cases increased by 75%, mainly due to changing age structures and population growth.\nA tumor is composed of various cellular and stromal components, eg tumor cells, inflammatory cells, blood vessels, acellular matrix, tumor capsule, fluid, mucin, or necrosis. The viable tumor burden is defined as the ratio of viable tumor area to the whole area of the tumor. The need for evaluation of viable tumor burden is increasing, as an assessment of response rates for chemoradiotherapy or proportion of tumor cells in genetic testing using tissue samples. Traditional pathologists use a semiquantitative grading system for residual tumor burden or report portion of necrosis indirectly indicating viable tumor burden.\nResults Challenge https://paip2019.grand-challenge.org\n","date":1571788860,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571788860,"objectID":"196dfed23debf5f6a5509fb762b844a9","permalink":"https://DAISYlabs.github.io/project/2019-paip-task2/","publishdate":"2019-10-23T00:01:00Z","relpermalink":"/project/2019-paip-task2/","section":"project","summary":"**7th rank of 17** unique teams in Task 2: Viable Tumor Burden Estimation","tags":null,"title":"PAIP 2019 Challenge - Task 2","type":"project"},{"authors":["Rüdiger Schmitz","Frederic Madesta","Maximilian Nielsen","René Werner"],"categories":null,"content":"Aim The goal of the challenge is to evaluate new and existing algorithms for liver cancer segmentation in whole-slide images (WSIs).\nBackground The liver is a visceral organ most often involved in the metastatic spread of cancer. For the best practice, early diagnosis of liver cancer is important but many people don\u0026rsquo;t even know that they have hepatitis. Hepatocellular Carcinoma(HCC) represents about 90% of primary liver cancers and constitutes a major global health problem. The incidence of HCC is increasing both in Korea and worldwide; it is amongst the leading causes of cancer mortality globally. Between 1990 and 2015 newly diagnosed HCC cases increased by 75%, mainly due to changing age structures and population growth.\nA tumor is composed of various cellular and stromal components, eg tumor cells, inflammatory cells, blood vessels, acellular matrix, tumor capsule, fluid, mucin, or necrosis. The viable tumor burden is defined as the ratio of viable tumor area to the whole area of the tumor. The need for evaluation of viable tumor burden is increasing, as an assessment of response rates for chemoradiotherapy or proportion of tumor cells in genetic testing using tissue samples. Traditional pathologists use a semiquantitative grading system for residual tumor burden or report portion of necrosis indirectly indicating viable tumor burden.\nResults Challenge https://paip2019.grand-challenge.org\n","date":1571788800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571788800,"objectID":"56a56b69c678f1fc0eaf61d376ea3d33","permalink":"https://DAISYlabs.github.io/project/2019-paip-task1/","publishdate":"2019-10-23T00:00:00Z","relpermalink":"/project/2019-paip-task1/","section":"project","summary":"**7th rank of 27** unique teams in Task 1: Liver Cancer Segmentation","tags":null,"title":"PAIP 2019 Challenge - Task 1","type":"project"},{"authors":["Frederic Madesta","Thilo Sentker","Rüdiger Schmitz","René Werner"],"categories":null,"content":"Aim The goal of this task was the segmentation of the gross target volume of lung cancer in chest CT scans:\nBackground Radiation therapy is one type of important cancer treatment for killing cancer cells with external beam radiation. Treatment planning is vital for the treatment, which sets up the radiation dose distribution for tumor and ordinary organs. The goal of planning is to ensure the cancer cells receiving enough radiation and to prevent normal cells in organs-at-risk (OAR) from being damaged too much. Organs-at-risk are usually the organs that are sensitive to radiation. For instance, optical nerves and chiasma in the head cannot receive too much radiation otherwise the patient risks losing his/her vision. Gross Target Volume (GTV) is the position and extent of gross tumor imaged by CT scans, i.e. what can be seen.\nOne important step in radiotherapy treatment planning is therefore to delineate the boundaries of tens of OARs and GTV in every slice of a patient\u0026rsquo;s CT scans, which is tedious and occupies much of oncologists\u0026rsquo; time. Automatic OAR and GTV delineation would substantially reduce the treatment planning time and therefore reduce the overall cost for radiotherapy.\nResults Challenge https://structseg2019.grand-challenge.org\n","date":1569888060,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888060,"objectID":"18e44c50cb4043f4bd3d9e6172f11fd9","permalink":"https://DAISYlabs.github.io/project/2019-structseg-task4/","publishdate":"2019-10-01T00:01:00Z","relpermalink":"/project/2019-structseg-task4/","section":"project","summary":"**7th rank of 17** unique teams in Task 4: Gross Target Volume segmentation of lung cancer","tags":null,"title":"StructSeg 2019 - Task 4","type":"project"},{"authors":["Mohsin Shaikh","Alexander Schlaefer","René Werner"],"categories":null,"content":"Aim The purpose of this challenge is to directly compare methods for segmentation of gray matter, white matter, cerebrospinal fluid, and other structures on 3T MRI scans of the brain, and to assess the effect of (large) pathologies on segmentation and volumetry.\nBackground Many algorithms for segmenting brain structures in MRI scans have been proposed over the years. Especially in such a well-established research area, there is a tremendous need for fair comparison of these methods with respect to accuracy and robustness. Although there is an increasing awareness of the importance of comparing different algorithms on the same data, many methods are still compared to previous versions of the same type of algorithm on privately held data. This complicates the choice for a certain brain segmentation method among a wide variety of available methods.\nThis challenge aims to directly compare automated brain segmentation methods. The output will be a ranking of techniques that robustly and accurately segment brain structure on MR brain images, both with and without pathology. We welcome both multi- and single-sequence (i.e. T1-weighted only) approaches.\nResults Challenge https://mrbrains18.isi.uu.nl\n","date":1537056000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537056000,"objectID":"58163c049b112fa9d482548c41ef84d3","permalink":"https://DAISYlabs.github.io/project/2018-mrbrains/","publishdate":"2018-09-16T00:00:00Z","relpermalink":"/project/2018-mrbrains/","section":"project","summary":"**7th rank of 40** unique teams in Task 2: Three Label Segmentation","tags":null,"title":"MR Brain Segmentation 2018 - MRBrainS18","type":"project"},{"authors":["Frederic Madesta","Thilo Sentker","Rüdiger Schmitz","René Werner"],"categories":null,"content":"Aim The goal of this task was the segmentation of six organ-at-risk in chest CT scans:\n left lung right lung spinal cord esophagus heart trachea  Background Radiation therapy is one type of important cancer treatment for killing cancer cells with external beam radiation. Treatment planning is vital for the treatment, which sets up the radiation dose distribution for tumor and ordinary organs. The goal of planning is to ensure the cancer cells receiving enough radiation and to prevent normal cells in organs-at-risk (OAR) from being damaged too much. Organs-at-risk are usually the organs that are sensitive to radiation. For instance, optical nerves and chiasma in the head cannot receive too much radiation otherwise the patient risks losing his/her vision. Gross Target Volume (GTV) is the position and extent of gross tumor imaged by CT scans, i.e. what can be seen.\nOne important step in radiotherapy treatment planning is therefore to delineate the boundaries of tens of OARs and GTV in every slice of a patient\u0026rsquo;s CT scans, which is tedious and occupies much of oncologists\u0026rsquo; time. Automatic OAR and GTV delineation would substantially reduce the treatment planning time and therefore reduce the overall cost for radiotherapy.\nResults Challenge https://structseg2019.grand-challenge.org\n","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"91d3b5762ddc5b845d5028c6d740454f","permalink":"https://DAISYlabs.github.io/project/2019-structseg-task3/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/project/2019-structseg-task3/","section":"project","summary":"**8th rank of 17** unique teams in Task 3: Organ-at-risk segmentation from chest CT scans","tags":null,"title":"StructSeg 2019 - Task 3","type":"project"},{"authors":["Ivo Matteo Baltruschat","Thilo Sentker","Frederic Madesta","Rüdiger Schmitz","Helge Kniep","Nils Gessert","René Werner"],"categories":null,"content":"Aim Submit automated predictions of lesion segmentation boundaries within dermoscopic images.\nBackground Skin cancer is the most common cancer globally, with melanoma being the most deadly form. Dermoscopy is a skin imaging modality that has demonstrated improvement for diagnosis of skin cancer compared to unaided visual inspection. However, clinicians should receive adequate training for those improvements to be realized. In order to make expertise more widely available, the International Skin Imaging Collaboration (ISIC) has developed the ISIC Archive, an international repository of dermoscopic images, for both the purposes of clinical training, and for supporting technical research toward automated algorithmic analysis by hosting the ISIC Challenges.\nResults Challenge https://challenge2018.isic-archive.com\n","date":1524700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524700800,"objectID":"5616e6c7b10370eff2227a83808ade4a","permalink":"https://DAISYlabs.github.io/project/2018-isic-task1/","publishdate":"2018-04-26T00:00:00Z","relpermalink":"/project/2018-isic-task1/","section":"project","summary":"**11th rank of 77** unique teams in Task 1: Lesion Boundary Segmentation","tags":null,"title":"ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection - Task 1","type":"project"},{"authors":["Ivo Matteo Baltruschat","Nils Gessert","Maximilian Nielsen","Rüdiger Schmitz","René Werner","André Gooßen"],"categories":null,"content":"Aim Th goal of this competition is to develop a model to classify (and if present, segment) pneumothorax from a set of chest radiographic images.\nBackground Imagine suddenly gasping for air, helplessly breathless for no apparent reason. Could it be a collapsed lung? In the future, your entry in this competition could predict the answer.\nPneumothorax can be caused by a blunt chest injury, damage from underlying lung disease, or most horrifying—it may occur for no obvious reason at all. On some occasions, a collapsed lung can be a life-threatening event.\nPneumothorax is usually diagnosed by a radiologist on a chest x-ray, and can sometimes be very difficult to confirm. An accurate AI algorithm to detect pneumothorax would be useful in a lot of clinical scenarios. AI could be used to triage chest radiographs for priority interpretation, or to provide a more confident diagnosis for non-radiologists.\nChallenge https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/\n","date":1566777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566777600,"objectID":"f8dea74d10783486ab1d5e897f0cfb49","permalink":"https://DAISYlabs.github.io/project/2019-ssim-pneu/","publishdate":"2019-08-26T00:00:00Z","relpermalink":"/project/2019-ssim-pneu/","section":"project","summary":"**Top 20% of 1475** unique teams in identifing Pneumothorax disease in chest x-rays","tags":null,"title":"SIIM-ACR Pneumothorax Segmentation","type":"project"},{"authors":["Rüdiger Schmitz","Frederic Madesta","Maximilian Nielsen","René Werner","Thomas Rösch"],"categories":null,"content":"","date":1564963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564963200,"objectID":"74bf423b40c1036eb2594147ff924638","permalink":"https://DAISYlabs.github.io/publication/2019schmitzpaip/","publishdate":"2019-08-05T00:00:00Z","relpermalink":"/publication/2019schmitzpaip/","section":"publication","summary":"Histopathologic diagnosis is dependent on simultaneous information from a broad range of scales, ranging from nuclear aberrations (≈ O(0.1 μm)) over cellular structures (≈ O(10 μm)) to the global tissue architecture (􏰀 O(1mm)). Bearing in mind which information is employed by human pathologists, we introduce and examine different strategies for the integration of multiple and widely separate spatial scales into common U-Net-based architectures. Based on this, we present a family of new, end-to-end trainable, multi-scale multi-encoder fully-convolutional neural networks for human modus operandi-inspired computer vision in histopathology.","tags":null,"title":"Multi-scale fully convolutional neural networks for histopathology image segmentation: from nuclear aberrations to the global tissue architecture","type":"publication"},{"authors":["Nils Gessert","Thilo Sentker","Frederic Madesta","Rüdiger Schmitz","Helge Kniep","Ivo Matteo Baltruschat","René Werner","Alexander Schlaefer"],"categories":null,"content":"","date":1558828800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558828800,"objectID":"49789e0e13c4e0fa8f2005a38e6e5492","permalink":"https://DAISYlabs.github.io/publication/2019gessertisicjournal/","publishdate":"2019-05-26T00:00:00Z","relpermalink":"/publication/2019gessertisicjournal/","section":"publication","summary":"Objective: This work addresses two key problems of skin lesion classification. The first problem is the effective use of high-resolution images with pretrained standard architectures for image classification. The second problem is the high class imbalance encountered in real-world multi-class datasets. Methods: To use high-resolution images, we propose a novel patch-based attention architecture that provides global context between small, high-resolution patches. We modify three pretrained architectures and study the performance of patch-based attention. To counter class imbalance problems, we compare oversampling, balanced batch sampling, and class-specific loss weighting. Additionally, we propose a novel diagnosis-guided loss weighting method which takes the method used for ground-truth annotation into account. Results: Our patch-based attention mechanism outperforms previous methods and improves the mean sensitivity by 7%. Class balancing significantly improves the mean sensitivity and we show that our diagnosis-guided loss weighting method improves the mean sensitivity by 3% over normal loss balancing. Conclusion: The novel patch-based attention mechanism can be integrated into pretrained architectures and provides global context between local patches while outperforming other patch-based methods. Hence, pretrained architectures can be readily used with high-resolution images without downsampling. The new diagnosis-guided loss weighting method outperforms other methods and allows for effective training when facing class imbalance. Significance: The proposed methods improve automatic skin lesion classification. They can be extended to other clinical applications where high-resolution image data and class imbalance are relevant.","tags":null,"title":"Skin Lesion Classification Using CNNs with Patch-Based Attention and Diagnosis-Guided Loss Weighting","type":"publication"},{"authors":["Ivo Matteo Baltruschat","Thilo Sentker","Frederic Madesta","Rüdiger Schmitz","Helge Kniep","Nils Gessert","René Werner","Tobias Knopp"],"categories":null,"content":"","date":1533427200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533427200,"objectID":"9a455fce49c97136755df5a35a0ed3f7","permalink":"https://DAISYlabs.github.io/publication/2018baltruschatisic/","publishdate":"2018-08-05T00:00:00Z","relpermalink":"/publication/2018baltruschatisic/","section":"publication","summary":"This manuscript summarizes our method and validation re- sults for the ISIC Challenge 2018 􏰃 Skin Lesion Analysis Towards Melanoma Detection 􏰃 Task 1: Lesion Boundary Segmentation. Aim of this task is to develop an approach that automatically segments skin lesions within dermoscopic images. Our convolutional neural network based approaches utilize pre-trained weights for the FCN, SegNet, and DeepLabv3+ (i.e. with the Xception network backbone) as initialization. After training our networks on 90% of all skin lesion images and building an ensemble out of four best performing models, our approach yields a mean thresholded jaccard-index of 76.0% for the ISIC task 1 validation dataset. The single best performing model achieved 80.2%.","tags":null,"title":"Ensemble Building of State-of-the-art Models for Skin Lesion Boundary Segmentation","type":"publication"},{"authors":["Nils Gessert","Thilo Sentker","Frederic Madesta","Rüdiger Schmitz","Helge Kniep","Ivo Matteo Baltruschat","René Werner","Alexander Schlaefer"],"categories":null,"content":"","date":1533427200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533427200,"objectID":"4f428a539c9b21746fc3a64ae9e4956e","permalink":"https://DAISYlabs.github.io/publication/2018gessertisic/","publishdate":"2018-08-05T00:00:00Z","relpermalink":"/publication/2018gessertisic/","section":"publication","summary":"In this paper we present the methods of our submission to the ISIC 2018 challenge for skin lesion diagnosis (Task 3). The dataset consists of 10000 images with seven image-level classes to be distinguished by an automated algorithm. We employ an ensemble of convolutional neural networks for this task. In particular, we fine-tune pretrained state-of-the-art deep learning models such as Densenet, SENet and ResNeXt. We identify heavy class imbalance as a key problem for this challenge and consider multiple balancing approaches such as loss weighting and balanced batch sampling. Another important feature of our pipeline is the use of a vast amount of unscaled crops for evaluation. Last, we consider meta learning approaches for the final predictions. Our team placed second at the challenge while being the best approach using only publicly available data.","tags":null,"title":"Skin Lesion Diagnosis using Ensembles, Unscaled Multi-Crop Evaluation and Loss Weighting","type":"publication"},{"authors":null,"categories":null,"content":"Angaben gemäß § 5 TMG Ivo Matteo Baltruschat\nBarmbekerstraße 152\n22299 Hamburg, Deutschland\nKontakt Telefon: +49 (0) 1577 39 88 93 0\nE-Mail: im.baltruschat@icloud.com\nVerbraucherstreitbeilegung/Universalschlichtungsstelle Wir sind nicht bereit oder verpflichtet, an Streitbeilegungsverfahren vor einer Verbraucherschlichtungsstelle teilzunehmen.\nHaftung für Inhalte Als Diensteanbieter sind wir gemäß § 7 Abs.1 TMG für eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich. Nach §§ 8 bis 10 TMG sind wir als Diensteanbieter jedoch nicht verpflichtet, übermittelte oder gespeicherte fremde Informationen zu überwachen oder nach Umständen zu forschen, die auf eine rechtswidrige Tätigkeit hinweisen.\nVerpflichtungen zur Entfernung oder Sperrung der Nutzung von Informationen nach den allgemeinen Gesetzen bleiben hiervon unberührt. Eine diesbezügliche Haftung ist jedoch erst ab dem Zeitpunkt der Kenntnis einer konkreten Rechtsverletzung möglich. Bei Bekanntwerden von entsprechenden Rechtsverletzungen werden wir diese Inhalte umgehend entfernen.\nHaftung für Links Unser Angebot enthält Links zu externen Websites Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb können wir für diese fremden Inhalte auch keine Gewähr übernehmen. Für die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf mögliche Rechtsverstöße überprüft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar.\nEine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.\nUrheberrecht Die durch die Seitenbetreiber erstellten Inhalte und Werke auf diesen Seiten unterliegen dem deutschen Urheberrecht. Die Vervielfältigung, Bearbeitung, Verbreitung und jede Art der Verwertung außerhalb der Grenzen des Urheberrechtes bedürfen der schriftlichen Zustimmung des jeweiligen Autors bzw. Erstellers. Downloads und Kopien dieser Seite sind nur für den privaten, nicht kommerziellen Gebrauch gestattet.\nSoweit die Inhalte auf dieser Seite nicht vom Betreiber erstellt wurden, werden die Urheberrechte Dritter beachtet. Insbesondere werden Inhalte Dritter als solche gekennzeichnet. Sollten Sie trotzdem auf eine Urheberrechtsverletzung aufmerksam werden, bitten wir um einen entsprechenden Hinweis. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Inhalte umgehend entfernen.\n","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"9b10c1f64082d3869fd4cb1f85809430","permalink":"https://DAISYlabs.github.io/terms/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/terms/","section":"","summary":"Angaben gemäß § 5 TMG Ivo Matteo Baltruschat\nBarmbekerstraße 152\n22299 Hamburg, Deutschland\nKontakt Telefon: +49 (0) 1577 39 88 93 0\nE-Mail: im.baltruschat@icloud.com\nVerbraucherstreitbeilegung/Universalschlichtungsstelle Wir sind nicht bereit oder verpflichtet, an Streitbeilegungsverfahren vor einer Verbraucherschlichtungsstelle teilzunehmen.","tags":null,"title":"Impressum","type":"page"}]